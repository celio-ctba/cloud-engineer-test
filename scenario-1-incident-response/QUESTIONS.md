# Scenario 1 ‚Äî Questions

Answer these questions in `answer-template/ANSWERS.md` under the Scenario 1 section.

---

## Question 1.1 ‚Äî First 10 Minutes

You've just been paged. You have 10 minutes before the next escalation tier is notified.

**What are your first 10-minute actions?**  

üí° **Resposta:** Meu foco imediato √© entender o raio da explos√£o, reunir informa√ß√µes cr√≠ticas e me comunicar de forma eficaz. Evitarei tomar quaisquer a√ß√µes disruptivas imediatas at√© que eu tenha uma hip√≥tese clara.

Consider:
- What do you check first and why?  
  üí° **Resposta:**  
      Confirmar o recebimento do alerta em `#prod-alerts` com: "Alerta recebido. Investigando."  
      Informar √† equipe que estou ciente, evitando esfor√ßos duplicados.  
      Revisar o painel de alarmes e eventos recentes.  Vou examinar o `CONTEXT.md` e `cloudwatch_alarms.json`.  Obter uma vis√£o geral de alto n√≠vel do que est√° disparando e a sequ√™ncia de eventos. Os principais alarmes s√£o lat√™ncia, erros 5xx, hosts n√£o saud√°veis e profundidade da fila SQS. A linha do tempo aponta para a implanta√ß√£o v2.5.0 como um gatilho potencial.    
  
- What information do you need to gather?  
  üí° **Resposta:**  
  Verificar a sa√∫de do servi√ßo ECS e do banco de dados Aurora.  
     Olhar os eventos do servi√ßo ECS (`ecs_service.log`) e as m√©tricas do RDS (`cloudwatch_metrics.json`, `rds_slowquery.log`).<br>
  O alarme `unhealthy-hosts` √© cr√≠tico. Preciso saber por que as tarefas est√£o falhando. CPU/conex√µes altas no BD s√£o um forte indicador de um problema no banco de dados.<br> Formular uma hip√≥tese r√°pida: Com base na implanta√ß√£o da v2.5.0 e nos logs de consulta lenta, minha hip√≥tese inicial √© que a nova consulta de recomenda√ß√£o est√° causando conten√ß√£o no banco de dados e alta lat√™ncia.<br> Isso me d√° uma linha espec√≠fica para investigar.
                
- Who do you communicate with?  
  üí° **Resposta:**  
            Postar uma breve atualiza√ß√£o em `#prod-alerts`: "Descoberta inicial: Alta lat√™ncia e erros se correlacionam com a implanta√ß√£o v2.5.0. Suspeita-se que uma nova consulta ao banco de dados seja a causa. Estou investigando a consulta e proporei um plano de mitiga√ß√£o nos pr√≥ximos 10 minutos. No momento, n√£o estou tomando nenhuma a√ß√£o."  Manter as partes interessadas informadas e gerenciar as expectativas. √â importante declarar o que eu *n√£o* estou fazendo para evitar p√¢nico ou a√ß√µes prematuras.    
- What do you NOT do yet?<br>
  üí° **Resposta**:
*   **Reverter imediatamente a implanta√ß√£o.** Embora seja um culpado prov√°vel, uma revers√£o √© disruptiva. Preciso ter certeza de que √© a decis√£o certa.
*   **Reiniciar servi√ßos.** Isso pode destruir dados forenses valiosos e pode n√£o resolver o problema subjacente.
*   **Desativar o WAF.** O WAF √© provavelmente um sintoma (bloqueando tentativas leg√≠timas), n√£o a causa. Desativ√°-lo poderia nos expor a amea√ßas reais.

---

## Question 1.2 ‚Äî Alarm Correlation

Multiple alarms fired in quick succession. Review the `cloudwatch_alarms.json` file.

**How do you correlate these alarms? What story do they tell?**
üí° **Resposta:**  
Os alarmes contam uma hist√≥ria clara de uma falha em cascata originada na camada da aplica√ß√£o e impactando todo o ciclo de vida da solicita√ß√£o.

Consider:
- Which alarm is the leading indicator?<br>
  _Indicador Principal:_ _plooral-api-p99-latency(14:17 UTC). Este foi o primeiro sinal de problema, indicando que a pr√≥pria aplica√ß√£o estava ficando lenta._
- Which alarms are symptoms vs. causes?
- Are any alarms misleading or red herrings?  
  üí° **Resposta:** <br>
  **_A Hist√≥ria:_**
    1.  **Alta Lat√™ncia (`plooral-api-p99-latency`):** A aplica√ß√£o come√ßa a levar mais tempo para processar as solicita√ß√µes. Esta √© a raiz do problema.
    2.  **Erros 5xx (`plooral-api-5xx-rate`):** √Ä medida que as solicita√ß√µes expiram, o ALB e outros servi√ßos upstream come√ßam a retornar erros 5xx. O `alb_access.log` mostra erros `504` (Gateway Timeout) e `502` (Bad Gateway).
    3.  **Hosts N√£o Saud√°veis (`plooral-api-unhealthy-hosts`):** As verifica√ß√µes de sa√∫de do ECS, que provavelmente est√£o atingindo um endpoint de verifica√ß√£o de sa√∫de agora lento, come√ßam a falhar. Isso faz com que o servi√ßo ECS recicle as tarefas, piorando o problema, pois as novas tarefas tamb√©m podem falhar. O `ecs_service.log` confirma isso, mostrando tarefas falhando com c√≥digos `504` e erros `OOMKilled`.
    4.  **Profundidade da Fila SQS (`plooral-tasks-queue-depth`):** A Lambda `plooral-worker`, que processa mensagens da fila SQS, tamb√©m √© provavelmente impactada pelo banco de dados lento. Ela n√£o consegue processar mensagens r√°pido o suficiente, fazendo com que a fila aumente. O `lambda.log` e `sqs_metrics.json` confirmam isso, mostrando timeouts do banco de dados e uma fila crescente.
    5.  **Pico de Bloqueios no WAF (`plooral-waf-block-spike`):** Este √© um **sintoma**, n√£o uma causa. √Ä medida que os usu√°rios encontram erros, eles tentam novamente suas solicita√ß√µes, levando a um pico de tr√°fego de usu√°rios leg√≠timos. Isso aciona a regra de limita√ß√£o de taxa do WAF. O `waf_sample_requests.log` mostra agentes de usu√°rio de apar√™ncia leg√≠tima sendo bloqueados. Esta √© uma pista falsa em termos de causa raiz, mas um indicador claro do impacto no usu√°rio.
    6.  **Conex√µes Aurora (`plooral-aurora-connections`):** Este √© um sintoma direto da consulta lenta. As consultas de longa dura√ß√£o est√£o mantendo as conex√µes abertas, levando ao esgotamento do pool de conex√µes.

---

## Question 1.3 ‚Äî Hypothesis Ranking

Based on your analysis of the artifacts, list your hypotheses for the root cause.

**Rank your hypotheses from most to least likely. Explain your reasoning.**

Format your answer as:

| Rank | Hypothesis | Supporting Evidence | Against Evidence |
|------|------------|---------------------|------------------|
| 1 | A nova implanta√ß√£o v2.5.0 introduziu uma consulta de banco de dados ineficiente que est√° causando alta lat√™ncia e conten√ß√£o de recursos. | - **Cronologia:** O incidente come√ßou minutos ap√≥s a conclus√£o da implanta√ß√£o v2.5.0. <br>- **Logs:** `rds_slowquery.log` mostra uma nova consulta muito cara (`-- NEW QUERY IN v2.5.0 - User Recommendations`) com `Query_time` e `Lock_time` altos a partir das 14:15 UTC. <br>- **M√©tricas:** `cloudwatch_metrics.json` mostra a CPU e as conex√µes do Aurora aumentando ap√≥s as 14:10 UTC. <br>- **Mudan√ßa no C√≥digo:** `CONTEXT.md` afirma explicitamente que a mudan√ßa da v2.5.0 foi uma "Nova consulta de banco de dados para recomenda√ß√µes de usu√°rios" que "n√£o foi revisada por um DBA". | Nenhuma. A evid√™ncia √© esmagadora. |
| 2 | Um ator malicioso est√° lan√ßando um ataque DDoS, causando a alta carga e acionando o WAF. | - **Alarme do WAF:** O alarme `plooral-waf-block-spike` est√° disparando. <br>- **Aumento de Tr√°fego:** `cloudwatch_metrics.json` mostra um leve aumento no `RequestCount`. | - **Logs do WAF:** `waf_sample_requests.log` mostra agentes de usu√°rio leg√≠timos e uma nota de que provavelmente s√£o novas tentativas. <br>- **Concentra√ß√£o Geogr√°fica:** O pico de tr√°fego √© de `ap-southeast-1`, que pode ser uma base de usu√°rios leg√≠tima. Um DDoS sofisticado provavelmente seria mais distribu√≠do. <br>- **A consulta lenta:** Um ataque DDoS n√£o explicaria o aparecimento s√∫bito de uma nova consulta lenta nos logs. |
| 3 | Uma depend√™ncia downstream (por exemplo, uma API externa) est√° lenta ou indispon√≠vel, fazendo com que as solicita√ß√µes fiquem presas. | - **Erros 5xx:** A aplica√ß√£o est√° retornando erros 5xx, que podem ser causados por falhas downstream. | - **Nenhuma Evid√™ncia:** N√£o h√° men√ß√£o de nenhuma depend√™ncia externa no diagrama de arquitetura ou nos logs. <br>- **M√©tricas do Banco de Dados:** As m√©tricas do Aurora apontam diretamente para o banco de dados como o gargalo, n√£o um servi√ßo externo. |

---

## Question 1.4 ‚Äî Immediate Mitigation

It's now 14:25 UTC. You need to stop the bleeding.

**What immediate mitigation steps do you take? In what order?**

For each step:
- What action do you take?
- What is the expected outcome?
- What could go wrong?
- How do you verify success?<br>
üí° **Resposta:** <br>

| Passo | A√ß√£o | Resultado Esperado | O que Pode Dar Errado? | Como Verificar o Sucesso |
|---|---|---|---|---|
| 1 | **Iniciar a Revers√£o (Rollback) do Servi√ßo ECS `plooral-api` para v2.4.1** | A consulta ineficiente ser√° removida da aplica√ß√£o. Isso deve reduzir imediatamente a carga no banco de dados. | A revers√£o pode falhar, ou a imagem v2.4.1 pode ter seus pr√≥prios problemas (improv√°vel, pois era a vers√£o est√°vel anterior). A infraestrutura (CodeDeploy) pode ter problemas. | - Monitorar os eventos do servi√ßo ECS para garantir que a revers√£o seja conclu√≠da com sucesso e que todas as tarefas estejam executando a v2.4.1. <br>- Observar a m√©trica `TargetResponseTime_p99` no CloudWatch; ela deve come√ßar a diminuir significativamente em minutos. |
| 2 | **Monitorar M√©tricas Chave** | Conforme a revers√£o avan√ßa, espero ver uma recupera√ß√£o r√°pida. | O sistema pode n√£o se recuperar, indicando um problema diferente ou adicional. | - **`plooral-api-p99-latency`:** Deve cair abaixo do limiar de 2000ms. <br>- **`plooral-api-5xx-rate`:** Deve cair para perto de zero. <br>- **`plooral-api-unhealthy-hosts`:** Deve ir para 0 √† medida que as tarefas se tornam saud√°veis. <br>- **`plooral-aurora-cpu` & `plooral-aurora-connections`:** Devem diminuir para os n√≠veis normais. <br>- **`plooral-tasks-queue-depth`:** Deve come√ßar a diminuir √† medida que a Lambda do worker consegue processar as mensagens novamente. |
| 3 | **Comunicar o Status** | Manter as partes interessadas informadas sobre a mitiga√ß√£o e recupera√ß√£o em andamento. | A m√° comunica√ß√£o pode causar confus√£o. | - Postar uma atualiza√ß√£o em `#prod-alerts`: "Mitiga√ß√£o em andamento. Revertendo `plooral-api` para v2.4.1 para resolver a suspeita de consulta ruim. Monitorando a recupera√ß√£o. Pr√≥xima atualiza√ß√£o em 5 minutos." <br>- Assim que as m√©tricas se recuperarem, postar: "A revers√£o foi conclu√≠da e as m√©tricas est√£o voltando ao normal. O incidente imediato est√° resolvido. Estamos agora em fase de monitoramento." |

---

## Question 1.5 ‚Äî Permanent Fix

After the incident is mitigated, you need to ensure it doesn't happen again.

**What is the root cause? What permanent fix do you propose?**

Consider:
- What code/config changes are needed?
- What process changes are needed?
- What guardrails should be added?<br>
üí° **Resposta:** <br>
    **Causa Raiz:** A implanta√ß√£o da `plooral-api` v2.5.0 introduziu uma nova consulta SQL n√£o otimizada e n√£o revisada para recomenda√ß√µes de usu√°rios. Esta consulta realizava um `CROSS JOIN` entre `users` e `jobs` e continha v√°rias subconsultas caras, levando a tempos de consulta extremamente longos, alta conten√ß√£o de bloqueio e, finalmente, esgotamento de recursos do banco de dados (CPU e conex√µes).

**Corre√ß√µes Permanentes:**

*   **Mudan√ßas no C√≥digo:**
    *   **Reescrever a Consulta:** A consulta de recomenda√ß√£o precisa ser completamente reescrita. O `CROSS JOIN` √© inaceit√°vel. A l√≥gica deve ser otimizada, provavelmente quebrando-a em consultas menores e mais direcionadas ou usando uma abordagem totalmente diferente (por exemplo, um mecanismo de recomenda√ß√£o pr√©-calculado).
    *   **Adicionar Indexa√ß√£o:** Analisar a consulta e adicionar os √≠ndices de banco de dados apropriados √†s tabelas envolvidas (`users`, `jobs`, `user_skills`, `job_skills`, `company_reviews`).
    *   **Implementar Timeouts e Circuit Breakers:** O c√≥digo da aplica√ß√£o deve ter timeouts para todas as consultas ao banco de dados e um padr√£o de circuit breaker para evitar que uma √∫nica consulta lenta derrube toda a aplica√ß√£o.

*   **Mudan√ßas no Processo:**
    *   **Revis√£o Obrigat√≥ria pelo DBA:** Todas as consultas de banco de dados novas ou modificadas devem ser revisadas e aprovadas por um DBA antes de serem mescladas na branch principal.
    *   **Teste de Carga:** Novas funcionalidades complexas como este mecanismo de recomenda√ß√£o devem ser testadas sob carga em um ambiente de homologa√ß√£o (staging) que espelhe a escala de produ√ß√£o. Isso teria capturado o problema de desempenho antes que chegasse √† produ√ß√£o.
    *   **Implanta√ß√µes Can√°rio (Canary Deployments):** Em vez de uma implanta√ß√£o cont√≠nua (rolling), use uma estrat√©gia de implanta√ß√£o can√°rio. Isso teria exposto o problema a um pequeno subconjunto de usu√°rios, permitindo uma revers√£o r√°pida com impacto m√≠nimo.

*   **Guardi√µes (Guardrails):**
    *   **Alarmes mais R√≠gidos no CloudWatch:**
        *   Implementar um alarme no `Lock_time` no log de consultas lentas.
        *   Diminuir o limiar para o alarme `p99-latency` para ser mais sens√≠vel.
        *   Adicionar um alarme para a utiliza√ß√£o de mem√≥ria do ECS para capturar coisas como o erro `OOMKilled`.
    *   **Revers√µes Automatizadas:** Configurar a implanta√ß√£o do ECS para reverter automaticamente com base em limiares de alarme espec√≠ficos do CloudWatch (por exemplo, se a taxa de 5xx exceder uma certa porcentagem por alguns minutos ap√≥s uma implanta√ß√£o).
    *   **An√°lise de Consultas no CI/CD:** Integrar uma ferramenta ao pipeline de CI/CD que analise consultas e sinalize poss√≠veis problemas de desempenho (por exemplo, `CROSS JOIN`, falta de √≠ndices).

---

## Question 1.6 ‚Äî Postmortem

The incident is resolved. You need to write a postmortem.

**Provide an outline of the postmortem document.**

*   **1. Sum√°rio Executivo:**
    *   Um incidente P0 ocorreu em 15 de janeiro de 2024, das 14:15 √†s 14:35 UTC (20 minutos), causando alta lat√™ncia, erros e degrada√ß√£o do servi√ßo para todos os usu√°rios. O incidente foi causado por uma nova consulta de banco de dados n√£o otimizada, implantada na vers√£o v2.5.0. O problema foi mitigado com a revers√£o da implanta√ß√£o para a vers√£o anterior.

*   **2. Resumo do Impacto:**
    *   **Impacto no Cliente:** Os usu√°rios experimentaram carregamentos de p√°gina lentos, erros (5xx) e incapacidade de acessar o servi√ßo. Um subconjunto de usu√°rios em `ap-southeast-1` foi bloqueado pelo WAF.
    *   **M√©tricas:**
        *   Lat√™ncia P99: Pico de 4.200ms
        *   Taxa de 5xx: Pico de 3.2%
        *   Profundidade da Fila SQS: Aumentou para mais de 14.000 mensagens
    *   **Impacto no Neg√≥cio:** Experi√™ncia do usu√°rio degradada, potencial perda de confian√ßa do usu√°rio.

*   **3. Linha do Tempo (UTC):**
    *   14:00: In√≠cio da implanta√ß√£o da `plooral-api` v2.5.0.
    *   14:05: Implanta√ß√£o conclu√≠da.
    *   14:15: Disparo do alarme `plooral-api-p99-latency`.
    *   14:17: Alerta do Slack recebido, in√≠cio do incidente.
    *   14:18: Disparo do alarme `plooral-api-unhealthy-hosts`.
    *   14:20: Disparo do alarme `plooral-tasks-queue-depth`.
    *   14:22: Disparo do alarme `plooral-waf-block-spike`.
    *   14:25: Engenheiro de plant√£o inicia a revers√£o para a v2.4.1.
    *   14:35: Revers√£o conclu√≠da, m√©tricas voltam ao normal. Incidente mitigado.
    *   14:45: Incidente declarado resolvido.

*   **4. An√°lise da Causa Raiz:**
    *   **Causa Direta:** O lan√ßamento da `plooral-api` v2.5.0 incluiu uma nova consulta SQL altamente ineficiente para recomenda√ß√µes de usu√°rios.
    *   **Fatores Contribuintes:**
        *   A consulta usava um `CROSS JOIN` e subconsultas caras, levando a uma alta carga no banco de dados.
        *   A nova consulta n√£o foi revisada por um DBA.
        *   A funcionalidade n√£o foi testada sob carga antes do lan√ßamento.
        *   A estrat√©gia de implanta√ß√£o cont√≠nua exp√¥s todos os usu√°rios ao problema de uma vez.

*   **5. Itens de A√ß√£o:**
    | # | Item de A√ß√£o | Respons√°vel | Prazo |
    |---|---|---|---|
    | 1 | Reescrever e otimizar a consulta de recomenda√ß√£o de usu√°rio. | @backend-lead | 22/01/2024 |
    | 2 | Implementar um processo de revis√£o obrigat√≥ria pelo DBA para todas as consultas novas/modificadas. | @head-of-engineering | 29/01/2024 |
    | 3 | Configurar um ambiente de homologa√ß√£o para testes de carga de novas funcionalidades. | @devops-lead | 12/02/2024 |
    | 4 | Configurar revers√µes de implanta√ß√£o automatizadas com base em alarmes chave do CloudWatch. | @devops-lead | 05/02/2024 |
    | 5 | Processar com seguran√ßa o backlog do SQS do incidente. | @backend-lead | 16/01/2024 |
    | 6 | Ajustar as regras de limita√ß√£o de taxa do WAF para serem mais resilientes a tempestades de novas tentativas. | @security-lead | 05/02/2024 |

*   **6. Li√ß√µes Aprendidas:**
    *   **O que correu bem:** O engenheiro de plant√£o identificou rapidamente a causa prov√°vel e executou uma revers√£o bem-sucedida. As m√©tricas e logs dispon√≠veis foram suficientes para diagnosticar o problema.
    *   **O que poderia ser melhorado:** Nossas verifica√ß√µes pr√©-implanta√ß√£o s√£o insuficientes. Precisamos introduzir revis√µes formais de DBA e testes de carga para mudan√ßas de alto impacto.
    *   **Onde tivemos sorte:** A revers√£o foi bem-sucedida e a infraestrutura subjacente estava est√°vel. Se o problema fosse mais complexo, a interrup√ß√£o poderia ter sido muito mais longa.

---

## Bonus Questions

### Bonus 1.A ‚Äî WAF False Positives

The WAF blocked legitimate traffic from `ap-southeast-1`. 

**How do you handle this without disabling the WAF entirely?**  

:bulb:**Resposta:** Ajustar o limite da taxa, o limite atual √© de 2000 solicita√ß√µes por 300 segundos, √© pouco para um novo storm, vamos aumentar esse limite, mas apenas para agentes de usu√°rio ou intervalos de IP espec√≠ficos e confi√°veis ‚Äã‚Äãse poss√≠vel.
          Direcionar a regra, est√° bloqueando solicita√ß√µes para /vi/recommendations, podemos criar uma mais espec√≠fica que se aplicasse um limite de taxa mais alto apenas para este ponto final ou aumentar temporariamente o limite para todos os endpoints at√© que o problema subjacente seja resolvido.
          Usar uma m√©trica diferente, em vez de apenas contar solicita√ß√µes, a regra do WAF pode ser baseada em uma combina√ß√£o de fatores, como contagem de solicita√ß√µes de um √∫nico IP "e" uma alta taxa de erros 5x desde a origem, isso permitiria ao WAF diferenciar entre um ataque malicioso e uma invas√£o.
          Criar uma lista de IPs permitidos, se tivermos um conjunto conhecido de intervalos de IPs confi√°veis (por exemplo, para parceiros corporativos), podemos adicion√°-los a uma lista de permiss√µes para ignorar a regra de limita√ß√£o de taxa.

### Bonus 1.B ‚Äî SQS Queue Backlog

After the incident, there are 15,000+ messages in the SQS queue.

**How do you safely process this backlog? What's your strategy?**  

üí° **Resposta:** Confirmar que a causa raiz (a consulta incorreta) seja resolvida. O Lambda `plooral-worker` continuar√° falhando se o banco de dados ainda est√° sob press√£o. Temporariamente dar um scale down, deixar o lambda como 0 para evitar que ele extraia mais mensagens da fila. Isso vai dar um backlog est√°vel para trabalhar. Inspecionar uma amostra de mensagens da fila (e o DLQ) para entender o que s√£o. S√£o todos iguais? Mesmo tipo? Podem ser reprocessados ‚Äã‚Äãcom seguran√ßa? Se sim, provavelmente s√£o uma mistura de user.recommendation.generated e outros eventos.

### Bonus 1.C ‚Äî Aurora Connection Exhaustion

The connection pool nearly exhausted (285/300).

**What changes would you make to prevent this in the future?**  

üí° **Resposta:** A solu√ß√£o mais eficaz √© implementar o Amazon RDS Proxy. Pooling de Conex√µes: O RDS Proxy ficaria entre a aplica√ß√£o e o banco de dados, compartilhando e reutilizando conex√µes de banco de dados. Isso reduziria drasticamente o n√∫mero de conex√µes necess√°rias no pr√≥prio banco de dados.  

   O RDS Proxy tamb√©m pode melhorar a resili√™ncia, continuando a aceitar conex√µes mesmo que o banco de dados esteja temporariamente indispon√≠vel, e pode ajudar a prevenir tempestades de conex√µes.  
   
   Aumentar o max_connections, esta √© uma corre√ß√£o de curto prazo, n√£o uma solu√ß√£o de longo prazo. Embora eu pudesse aumentar o par√¢metro max_connections no cluster Aurora, √© melhor resolver o problema de gerenciamento de conex√µes subjacente.  
   
   Pooling de Conex√µes do Lado da Aplica√ß√£o, Garantir que a aplica√ß√£o esteja usando uma biblioteca de pool de conex√µes moderna e eficiente. No entanto, em um ambiente sem servidor como o Fargate, onde as tarefas podem aumentar e diminuir rapidamente, uma solu√ß√£o centralizada como o RDS Proxy √© superior.  
   
   Timeouts de Consulta, Como mencionado na corre√ß√£o permanente, implementar timeouts de consulta estritos na aplica√ß√£o evitaria que uma √∫nica consulta de longa dura√ß√£o mantivesse uma conex√£o aberta indefinidamente.       

